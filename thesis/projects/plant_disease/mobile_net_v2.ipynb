{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90297e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from thesis.utils.pytorch import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1eccce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 55448\n",
      "Train size: 44358\n",
      "Val size: 5544\n",
      "Test size: 5546\n"
     ]
    }
   ],
   "source": [
    "# Define data transforms\n",
    "# MobileNetV2 expects 224x224 input images and specific normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),          # phóng to rồi crop ngẫu nhiên vùng 224x224\n",
    "        transforms.RandomHorizontalFlip(p=0.5),     # lật ngang ảnh ngẫu nhiên\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # thay đổi màu sắc\n",
    "        transforms.RandomRotation(degrees=15),      # xoay ngẫu nhiên ±15 độ\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # dịch ảnh\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5), # hiệu ứng phối cảnh\n",
    "        transforms.ToTensor(),                      # chuyển thành tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([ # Often same as validation for consistent evaluation\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "# base_dir = \"/Users/anand/Desktop/1mg/repos/thesis/thesis/data/PlantDoc-Dataset\"\n",
    "base_dir = \"/Users/anand/Desktop/temp/Data for Identification of Plant Leaf Diseases Using a 9-layer Deep Convolutional Neural Network/Plant_leave_diseases_dataset_without_augmentation\"\n",
    "base_dataset = datasets.ImageFolder(base_dir)\n",
    "\n",
    "total_size = len(base_dataset)\n",
    "print('Total size:', total_size)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "print('Train size:', train_size)\n",
    "print('Val size:', val_size)\n",
    "print('Test size:', test_size)\n",
    "\n",
    "train_data, val_data, test_data = random_split(\n",
    "    base_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_data.dataset.transform = data_transforms[\"train\"]\n",
    "val_data.dataset.transform = data_transforms[\"val\"]\n",
    "test_data.dataset.transform = data_transforms[\"test\"]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd2cb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# These give you the label for each sample in the subset\n",
    "train_labels = [label for _, label in train_data]\n",
    "val_labels = [label for _, label in val_data]\n",
    "test_labels = [label for _, label in test_data]\n",
    "\n",
    "train_counters = Counter(train_labels)\n",
    "val_counters =  Counter(val_labels)\n",
    "test_counters = Counter(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "626c797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n"
     ]
    }
   ],
   "source": [
    "x = list(train_counters.keys())\n",
    "x.sort()\n",
    "print(x)\n",
    "\n",
    "y = list(val_counters.keys())\n",
    "y.sort()\n",
    "print(y)\n",
    "\n",
    "z = list(test_counters.keys())\n",
    "z.sort()\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04ef627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd1aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available quantization engines: ['qnnpack', 'none']\n",
      "Using quantization engine: qnnpack\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Quantisation step\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision.models\n",
    "\n",
    "# Check what backends are available\n",
    "print(\"Available quantization engines:\", torch.backends.quantized.supported_engines)\n",
    "\n",
    "# Use the first available backend\n",
    "if torch.backends.quantized.supported_engines:\n",
    "    torch.backends.quantized.engine = torch.backends.quantized.supported_engines[0]\n",
    "    print(f\"Using quantization engine: {torch.backends.quantized.engine}\")\n",
    "else:\n",
    "    print(\"No quantization engines available\")\n",
    "\n",
    "model = torchvision.models.mobilenet_v3_large(weights=\"DEFAULT\")\n",
    "model = model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "913c72a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  39\n",
      "Classifier: Sequential(\n",
      "  (0): Linear(in_features=960, out_features=1280, bias=True)\n",
      "  (1): Hardswish()\n",
      "  (2): Dropout(p=0.2, inplace=True)\n",
      "  (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "No of features:  1280\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.mobilenet_v3_large(weights=\"DEFAULT\")\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(base_dataset.classes) \n",
    "print(\"Num classes: \", num_classes)\n",
    "\n",
    "# Check classifier structure and get input features\n",
    "print(\"Classifier:\", model.classifier)\n",
    "\n",
    "# For MobileNetV3, the final layer is usually at index -1 or index 3\n",
    "# Let's try the last layer\n",
    "final_layer = model.classifier[-1]  # or try model.classifier[3]\n",
    "in_features = final_layer.in_features\n",
    "print(\"No of features: \", in_features)\n",
    "\n",
    "# Replace the final layer\n",
    "model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze feature extraction layers\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Setup loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb2815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device mps\n",
      "============================== Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/694 [00:00<?, ?it/s]/Users/anand/Desktop/1mg/repos/thesis/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Train: 100%|██████████| 694/694 [01:45<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9047\t|\tLoss: 0.3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:54<00:00, 101.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9522\t|\tLoss: 0.1361\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:43<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9596\t|\tLoss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:55<00:00, 100.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9620\t|\tLoss: 0.1167\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:44<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9730\t|\tLoss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:55<00:00, 99.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9609\t|\tLoss: 0.1150\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:43<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9784\t|\tLoss: 0.0640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:54<00:00, 101.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9602\t|\tLoss: 0.1188\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:45<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9837\t|\tLoss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:55<00:00, 100.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9639\t|\tLoss: 0.1129\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:45<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9846\t|\tLoss: 0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:52<00:00, 104.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9636\t|\tLoss: 0.1180\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:43<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9867\t|\tLoss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:55<00:00, 99.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9695\t|\tLoss: 0.1073\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:44<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9853\t|\tLoss: 0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:54<00:00, 101.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9693\t|\tLoss: 0.1160\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:44<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9871\t|\tLoss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:53<00:00, 104.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9690\t|\tLoss: 0.1271\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 694/694 [01:42<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Train:\t|\tAccuracy: 0.9903\t|\tLoss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 5546/5546 [00:53<00:00, 103.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Valid:\t|\tAccuracy: 0.9679\t|\tLoss: 0.1324\n",
      "========================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "============================== Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   5%|▌         | 36/694 [00:05<01:37,  6.77it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "print(\"device\", device)\n",
    "train(\"mobile_net_v3\", num_epochs, model, train_data, train_loader, test_data, test_loader, criterion, optimizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
